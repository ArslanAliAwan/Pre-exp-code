{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from copy import copy, deepcopy\n",
    "from scipy.io import arff\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from sklearn.metrics.pairwise import euclidean_distances, pairwise_distances\n",
    "from sklearn.utils import check_random_state\n",
    "from scipy.spatial import distance\n",
    "from tslearn.soft_dtw_fast import *\n",
    "from tslearn.cysax import *\n",
    "from tslearn.metrics import dtw, dtw_path,dtw_path_from_metric,soft_dtw\n",
    "from tslearn.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Training and Testing Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension1_TRAIN.arff')\n",
    "data2 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension2_TRAIN.arff')\n",
    "data3 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension3_TRAIN.arff')\n",
    "\n",
    "Test_data1 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension1_TEST.arff')\n",
    "Test_data2 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension2_TEST.arff')\n",
    "Test_data3 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension3_TEST.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D1 = pd.DataFrame(data1[0])\n",
    "df_D2 = pd.DataFrame(data2[0])\n",
    "df_D3 = pd.DataFrame(data3[0])\n",
    "\n",
    "Test_df_D1 = pd.DataFrame(Test_data1[0])\n",
    "Test_df_D2 = pd.DataFrame(Test_data2[0])\n",
    "Test_df_D3 = pd.DataFrame(Test_data3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Over the data, as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D1 =df_D1.apply(lambda x : x.fillna(method='ffill'), axis=1) \n",
    "df_D2 =df_D2.apply(lambda x : x.fillna(method='ffill'), axis=1)\n",
    "df_D3 =df_D3.apply(lambda x : x.fillna(method='ffill'), axis=1) \n",
    "\n",
    "Test_df_D1 =Test_df_D1.apply(lambda x : x.fillna(method='ffill'), axis=1) \n",
    "Test_df_D2 =Test_df_D2.apply(lambda x : x.fillna(method='ffill'), axis=1)\n",
    "Test_df_D3 =Test_df_D3.apply(lambda x : x.fillna(method='ffill'), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D1 = df_D1.drop('target', axis=1)\n",
    "df_D2 = df_D2.drop('target', axis=1)\n",
    "df_D3 = df_D3.drop('target', axis=1)\n",
    "\n",
    "Test_df_D1 = Test_df_D1.drop('target', axis=1)\n",
    "Test_df_D2 = Test_df_D2.drop('target', axis=1)\n",
    "Test_df_D3 = Test_df_D3.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sort_Dim_1 = np.expand_dims(df_D1.values.reshape(-1),axis=1)\n",
    "Sort_Dim_2 = np.expand_dims(df_D2.values.reshape(-1),axis=1)\n",
    "Sort_Dim_3 = np.expand_dims(df_D3.values.reshape(-1),axis=1)\n",
    "\n",
    "Sort_Test_Dim_1 = np.expand_dims(Test_df_D1.values.reshape(-1),axis=1)\n",
    "Sort_Test_Dim_2 = np.expand_dims(Test_df_D2.values.reshape(-1),axis=1)\n",
    "Sort_Test_Dim_3 = np.expand_dims(Test_df_D3.values.reshape(-1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_View = np.concatenate((Sort_Dim_1, Sort_Dim_2),axis=1)\n",
    "Training_View = np.concatenate((Training_View, Sort_Dim_3),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13015 ,  0.071323,  0.899306],\n",
       "       [-0.183121,  0.083973,  1.157239],\n",
       "       [-0.234104,  0.085534,  1.320469],\n",
       "       ...,\n",
       "       [-0.248272,  0.009383, -1.387357],\n",
       "       [-0.248272,  0.009383, -1.387357],\n",
       "       [-0.248272,  0.009383, -1.387357]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_View = np.concatenate((Sort_Test_Dim_1, Sort_Test_Dim_2),axis=1)\n",
    "Testing_View = np.concatenate((Testing_View, Sort_Test_Dim_3),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalarray_test_data = Testing_View[:][0:182]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 3)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalarray_test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_rows = 258804\n",
    "Sample_Percentage = 0\n",
    "Number_of_run= 0\n",
    "Length_RTS = 0\n",
    "global Sub_Sample_copy_PTS \n",
    "Training_Results_List = []\n",
    "PTS_Results_List = []\n",
    "Store_Avg_list = []\n",
    "Counter = 0 \n",
    "dictionary = dict()\n",
    "dictionary_RTS = dict()\n",
    "dictionary_RTS_all = dict()\n",
    "dictionary_PTS = dict()\n",
    "dictionary_PTS_for_all_change = dict()\n",
    "RTS_short_list_Results_List = []\n",
    "Starting_point = Testing_View[:][0:1]\n",
    "End_point = Testing_View[:][181:182]\n",
    "Length_RTS = 118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepared One View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "One_view = Training_View[:][:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258804, 3)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_view.shape # contains whole training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/arslanaliawan/Desktop/One_view', 'wb') as f:\n",
    "    \n",
    "    pickle.dump(One_view, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/arslanaliawan/Desktop/One_view', 'rb') as f:\n",
    "    One_view = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258804, 3)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_view.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take Sample of random rows (some specific %) from One_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rand_instances=int(len(One_view)*delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_instance_selection=np.random.randint(len(One_view), size=num_rand_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_instance_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the original instances of Training TS from above indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for x in range(len(random_instance_selection)):\n",
    "    \n",
    "    Index = random_instance_selection[x]\n",
    "    a.append(list(One_view[Index]))\n",
    "Subsample_one_view_array = np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 3)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subsample_one_view_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/arslanaliawan/Desktop/Subsample_one_view_array', 'wb') as f:\n",
    "    \n",
    "    pickle.dump(Subsample_one_view_array, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/arslanaliawan/Desktop/Subsample_one_view_array', 'rb') as f:\n",
    "    Subsample_one_view_array = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Similarity matrix of Sample One_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_similarity_matrix(Subsample_one_view_array):\n",
    "    ED_Matrix = distance.cdist(Subsample_one_view_array, Subsample_one_view_array, 'euclidean')\n",
    "    return ED_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_output = generate_similarity_matrix(Subsample_one_view_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/arslanaliawan/Desktop/similarity_output', 'wb') as f:\n",
    "    \n",
    "    pickle.dump(similarity_output, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/arslanaliawan/Desktop/similarity_output', 'rb') as f:\n",
    "    similarity_output = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 258)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for RTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_random_row(One_view,Length_RTS):\n",
    "    \n",
    "    number_of_rows = One_view.shape[0]\n",
    "    random_indices = np.random.choice(number_of_rows, size=Length_RTS, replace=False)\n",
    "    random_rows = One_view[random_indices, :]\n",
    "    return random_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adding_start_end_point(random_rows):\n",
    "    Output_TS = np.concatenate((Starting_point, random_rows),axis=0)\n",
    "    Output_TS = np.concatenate((Output_TS, End_point),axis=0)\n",
    "    return Output_TS   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_Random_DTW(Output_TS,Length_RTS):\n",
    "    path, dist = dtw_path(finalarray_test_data, Output_TS)\n",
    "    if(dist>0 and Length_RTS >100 ):\n",
    "        \n",
    "        RTS_short_list_Results_List.append(dist)  \n",
    "    else:\n",
    "        RTS_short_list_Results_List.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_methods_RTS(Subsample_one_view_array,Length_RTS):\n",
    "    \n",
    "    random_rows = Get_random_row(Subsample_one_view_array,Length_RTS)\n",
    "    Output_TS = Adding_start_end_point(random_rows)\n",
    "    Calculate_Random_DTW(Output_TS,Length_RTS) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for PTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adding_start_end_point_PTS(Com_SM,i):\n",
    "    \n",
    "    if(i==1):\n",
    "        Starting_point = Testing_View[:][0:1]\n",
    "        End_point = Testing_View[:][181:182]\n",
    "        SP_Matrix_1 = distance.cdist(Starting_point, Subsample_one_view_array, 'euclidean')\n",
    "        SP_Matrix_2 = distance.cdist(Starting_point, Starting_point, 'euclidean')\n",
    "        SP_Matrix_3 = distance.cdist(Starting_point, End_point, 'euclidean')\n",
    "        EP_Matrix_1 = distance.cdist(End_point, Subsample_one_view_array, 'euclidean')\n",
    "        EP_Matrix_2 = distance.cdist(End_point, Starting_point, 'euclidean')\n",
    "        EP_Matrix_3 = distance.cdist(End_point, End_point, 'euclidean')\n",
    "        SP_Matrix = np.concatenate((SP_Matrix_1, SP_Matrix_2),axis=1)\n",
    "        SP_Matrix = np.concatenate((SP_Matrix, SP_Matrix_3),axis=1)\n",
    "        EP_Matrix = np.concatenate((EP_Matrix_1, EP_Matrix_2),axis=1)\n",
    "        EP_Matrix = np.concatenate((EP_Matrix, EP_Matrix_3),axis=1)\n",
    "        Com_SM = np.concatenate((similarity_output, SP_Matrix_1),axis=0)\n",
    "        Com_SM = np.concatenate((Com_SM, EP_Matrix_1),axis=0)\n",
    "        Com_SM = np.concatenate((Com_SM, SP_Matrix.T),axis=1)\n",
    "        Com_SM = np.concatenate((Com_SM, EP_Matrix.T),axis=1)\n",
    "    else:\n",
    "        p = 182\n",
    "        Starting_point = Testing_View[:][((p*i)-p):(p*(i-1))+1]\n",
    "        End_point = Testing_View[:][((p*i)-1):p*i]\n",
    "        SP_Matrix_1 = distance.cdist(Starting_point, Subsample_one_view_array, 'euclidean')\n",
    "        SP_Matrix_2 = distance.cdist(Starting_point, Starting_point, 'euclidean')\n",
    "        SP_Matrix_3 = distance.cdist(Starting_point, End_point, 'euclidean')\n",
    "        EP_Matrix_1 = distance.cdist(End_point, Subsample_one_view_array, 'euclidean')\n",
    "        EP_Matrix_2 = distance.cdist(End_point, Starting_point, 'euclidean')\n",
    "        EP_Matrix_3 = distance.cdist(End_point, End_point, 'euclidean')\n",
    "        SP_Matrix = np.concatenate((SP_Matrix_1, SP_Matrix_2),axis=1)\n",
    "        SP_Matrix = np.concatenate((SP_Matrix, SP_Matrix_3),axis=1)\n",
    "        EP_Matrix = np.concatenate((EP_Matrix_1, EP_Matrix_2),axis=1)\n",
    "        EP_Matrix = np.concatenate((EP_Matrix, EP_Matrix_3),axis=1)\n",
    "        Com_SM = np.concatenate((similarity_output, SP_Matrix_1),axis=0)\n",
    "        Com_SM = np.concatenate((Com_SM, EP_Matrix_1),axis=0)\n",
    "        Com_SM = np.concatenate((Com_SM, SP_Matrix.T),axis=1)\n",
    "        Com_SM = np.concatenate((Com_SM, EP_Matrix.T),axis=1)       \n",
    "\n",
    "\n",
    "    return Com_SM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(SM_PTS):\n",
    "    G = nx.from_numpy_matrix(SM_PTS, create_using=nx.Graph)\n",
    "    layout = nx.spring_layout(G)\n",
    "    sizes = len(SM_PTS)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_MST(G):\n",
    "    layout = nx.spring_layout(G)\n",
    "    T=nx.minimum_spanning_tree(G)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Dijkstra(T):\n",
    "    Dij = nx.dijkstra_path(T,258,259)\n",
    "    return Dij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doing_miscellaneous_work(Dijkstra_output):\n",
    "    global Counter\n",
    "    a = []\n",
    "    for x in range(len(Dijkstra_output)):\n",
    "        Counter = Counter +1 \n",
    "        Index = Dijkstra_output[x]\n",
    "        a.append(list(One_view[Index]))\n",
    "    P_TS = np.array(a)\n",
    "    return P_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_DTW_PTS(Miscellaneous_output):\n",
    "    path, dist = dtw_path(finalarray_test_data, Miscellaneous_output)\n",
    "    if(dist>0):\n",
    "        PTS_Results_List.append(dist)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_all_fun(SM_PTS):\n",
    "    \n",
    "    graph_output = generate_graph(SM_PTS)\n",
    "    MST_output_1 =  generate_MST(graph_output)\n",
    "    Dijkstra_output = generate_Dijkstra(MST_output_1)\n",
    "    Miscellaneous_output = doing_miscellaneous_work(Dijkstra_output)\n",
    "    generate_DTW_PTS(Miscellaneous_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range (1,3):\n",
    "    \n",
    "    interation_num = 4\n",
    "    for i in range (1,interation_num):\n",
    "        SM_PTS = Adding_start_end_point_PTS(Com_SM,i)\n",
    "        Run_all_fun(SM_PTS)\n",
    "        \n",
    "        run_all_methods_RTS(Subsample_one_view_array,Length_RTS)\n",
    "        \n",
    "     \n",
    "    dictionary_PTS[y] = PTS_Results_List\n",
    "    PTS_Results_List = []\n",
    "    dictionary_RTS[y] = RTS_short_list_Results_List\n",
    "    RTS_short_list_Results_List = []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [11.684419403960902, 11.51537774014812, 11.887147622602242],\n",
       " 2: [11.684419403960902, 11.51537774014812, 11.887147622602242]}"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_PTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [19.722038308484315, 18.55856130294595, 18.98630637216879],\n",
       " 2: [18.17262903836858, 19.009718495584895, 19.14864042202174]}"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_RTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
