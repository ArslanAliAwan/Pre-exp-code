{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from copy import copy, deepcopy\n",
    "from scipy.io import arff\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from sklearn.metrics.pairwise import euclidean_distances, pairwise_distances\n",
    "from sklearn.utils import check_random_state\n",
    "from scipy.spatial import distance\n",
    "from tslearn.soft_dtw_fast import *\n",
    "from tslearn.cysax import *\n",
    "from tslearn.metrics import dtw, dtw_path,dtw_path_from_metric,soft_dtw\n",
    "from tslearn.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Training and Testing Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension1_TRAIN.arff')\n",
    "data2 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension2_TRAIN.arff')\n",
    "data3 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension3_TRAIN.arff')\n",
    "\n",
    "Test_data1 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension1_TEST.arff')\n",
    "Test_data2 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension2_TEST.arff')\n",
    "Test_data3 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension3_TEST.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D1 = pd.DataFrame(data1[0])\n",
    "df_D2 = pd.DataFrame(data2[0])\n",
    "df_D3 = pd.DataFrame(data3[0])\n",
    "\n",
    "Test_df_D1 = pd.DataFrame(Test_data1[0])\n",
    "Test_df_D2 = pd.DataFrame(Test_data2[0])\n",
    "Test_df_D3 = pd.DataFrame(Test_data3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Over the data, as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D1 =df_D1.apply(lambda x : x.fillna(method='ffill'), axis=1) \n",
    "df_D2 =df_D2.apply(lambda x : x.fillna(method='ffill'), axis=1)\n",
    "df_D3 =df_D3.apply(lambda x : x.fillna(method='ffill'), axis=1) \n",
    "\n",
    "Test_df_D1 =Test_df_D1.apply(lambda x : x.fillna(method='ffill'), axis=1) \n",
    "Test_df_D2 =Test_df_D2.apply(lambda x : x.fillna(method='ffill'), axis=1)\n",
    "Test_df_D3 =Test_df_D3.apply(lambda x : x.fillna(method='ffill'), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D1 = df_D1.drop('target', axis=1)\n",
    "df_D2 = df_D2.drop('target', axis=1)\n",
    "df_D3 = df_D3.drop('target', axis=1)\n",
    "\n",
    "Test_df_D1 = Test_df_D1.drop('target', axis=1)\n",
    "Test_df_D2 = Test_df_D2.drop('target', axis=1)\n",
    "Test_df_D3 = Test_df_D3.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sort_Dim_1 = np.expand_dims(df_D1.values.reshape(-1),axis=1)\n",
    "Sort_Dim_2 = np.expand_dims(df_D2.values.reshape(-1),axis=1)\n",
    "Sort_Dim_3 = np.expand_dims(df_D3.values.reshape(-1),axis=1)\n",
    "\n",
    "Sort_Test_Dim_1 = np.expand_dims(Test_df_D1.values.reshape(-1),axis=1)\n",
    "Sort_Test_Dim_2 = np.expand_dims(Test_df_D2.values.reshape(-1),axis=1)\n",
    "Sort_Test_Dim_3 = np.expand_dims(Test_df_D3.values.reshape(-1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_View = np.concatenate((Sort_Dim_1, Sort_Dim_2),axis=1)\n",
    "Training_View = np.concatenate((Training_View, Sort_Dim_3),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13015 ,  0.071323,  0.899306],\n",
       "       [-0.183121,  0.083973,  1.157239],\n",
       "       [-0.234104,  0.085534,  1.320469],\n",
       "       ...,\n",
       "       [-0.248272,  0.009383, -1.387357],\n",
       "       [-0.248272,  0.009383, -1.387357],\n",
       "       [-0.248272,  0.009383, -1.387357]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_View = np.concatenate((Sort_Test_Dim_1, Sort_Test_Dim_2),axis=1)\n",
    "Testing_View = np.concatenate((Testing_View, Sort_Test_Dim_3),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalarray_test_data = Testing_View[:][0:182]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalarray_test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_rows = 258804\n",
    "Sample_Percentage = 0\n",
    "Number_of_run= 0\n",
    "Length_RTS = 0\n",
    "global Sub_Sample_copy_PTS \n",
    "Training_Results_List = []\n",
    "PTS_Results_List = []\n",
    "Store_Avg_list = []\n",
    "Counter = 0 \n",
    "dictionary = dict()\n",
    "dictionary_RTS = dict()\n",
    "dictionary_RTS_all = dict()\n",
    "dictionary_PTS = dict()\n",
    "dictionary_PTS_for_all_change = dict()\n",
    "RTS_short_list_Results_List = []\n",
    "Starting_point = Testing_View[:][0:1]\n",
    "End_point = Testing_View[:][181:182]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepared One View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "One_view = Training_View[:][:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258804, 3)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_view.shape # contains whole training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/arslanaliawan/Desktop/One_view', 'wb') as f:\n",
    "    \n",
    "    pickle.dump(One_view, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/arslanaliawan/Desktop/One_view', 'rb') as f:\n",
    "    One_view = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258804, 3)"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_view.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take Sample of random rows (some specific %) from One_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rand_instances=int(len(One_view)*delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_instance_selection=np.random.randint(len(One_view), size=num_rand_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_instance_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the original instances of Training TS from above indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for x in range(len(random_instance_selection)):\n",
    "    \n",
    "    Index = random_instance_selection[x]\n",
    "    a.append(list(One_view[Index]))\n",
    "Subsample_one_view_array = np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 3)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Subsample_one_view_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/arslanaliawan/Desktop/Subsample_one_view_array', 'wb') as f:\n",
    "    \n",
    "    pickle.dump(Subsample_one_view_array, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/arslanaliawan/Desktop/Subsample_one_view_array', 'rb') as f:\n",
    "    Subsample_one_view_array = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Similarity matrix of Sample One_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_similarity_matrix(Subsample_one_view_array):\n",
    "    ED_Matrix = distance.cdist(Subsample_one_view_array, Subsample_one_view_array, 'euclidean')\n",
    "    return ED_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_output = generate_similarity_matrix(Subsample_one_view_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/arslanaliawan/Desktop/similarity_output', 'wb') as f:\n",
    "    \n",
    "    pickle.dump(similarity_output, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/arslanaliawan/Desktop/similarity_output', 'rb') as f:\n",
    "    similarity_output = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258, 258)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adding_start_end_point_PTS(Com_SM,i):\n",
    "    \n",
    "    if(i==1):\n",
    "        Starting_point = Testing_View[:][0:1]\n",
    "        End_point = Testing_View[:][181:182]\n",
    "        SP_Matrix_1 = distance.cdist(Starting_point, Subsample_one_view_array, 'euclidean')\n",
    "        SP_Matrix_2 = distance.cdist(Starting_point, Starting_point, 'euclidean')\n",
    "        SP_Matrix_3 = distance.cdist(Starting_point, End_point, 'euclidean')\n",
    "        EP_Matrix_1 = distance.cdist(End_point, Subsample_one_view_array, 'euclidean')\n",
    "        EP_Matrix_2 = distance.cdist(End_point, Starting_point, 'euclidean')\n",
    "        EP_Matrix_3 = distance.cdist(End_point, End_point, 'euclidean')\n",
    "        SP_Matrix = np.concatenate((SP_Matrix_1, SP_Matrix_2),axis=1)\n",
    "        SP_Matrix = np.concatenate((SP_Matrix, SP_Matrix_3),axis=1)\n",
    "        EP_Matrix = np.concatenate((EP_Matrix_1, EP_Matrix_2),axis=1)\n",
    "        EP_Matrix = np.concatenate((EP_Matrix, EP_Matrix_3),axis=1)\n",
    "        Com_SM = np.concatenate((similarity_output, SP_Matrix_1),axis=0)\n",
    "        Com_SM = np.concatenate((Com_SM, EP_Matrix_1),axis=0)\n",
    "        Com_SM = np.concatenate((Com_SM, SP_Matrix.T),axis=1)\n",
    "        Com_SM = np.concatenate((Com_SM, EP_Matrix.T),axis=1)\n",
    "    else:\n",
    "        p = 182\n",
    "        Starting_point = Testing_View[:][((p*i)-p):(p*(i-1))+1]\n",
    "        End_point = Testing_View[:][((p*i)-1):p*i]\n",
    "        SP_Matrix_1 = distance.cdist(Starting_point, Subsample_one_view_array, 'euclidean')\n",
    "        SP_Matrix_2 = distance.cdist(Starting_point, Starting_point, 'euclidean')\n",
    "        SP_Matrix_3 = distance.cdist(Starting_point, End_point, 'euclidean')\n",
    "        EP_Matrix_1 = distance.cdist(End_point, Subsample_one_view_array, 'euclidean')\n",
    "        EP_Matrix_2 = distance.cdist(End_point, Starting_point, 'euclidean')\n",
    "        EP_Matrix_3 = distance.cdist(End_point, End_point, 'euclidean')\n",
    "        SP_Matrix = np.concatenate((SP_Matrix_1, SP_Matrix_2),axis=1)\n",
    "        SP_Matrix = np.concatenate((SP_Matrix, SP_Matrix_3),axis=1)\n",
    "        EP_Matrix = np.concatenate((EP_Matrix_1, EP_Matrix_2),axis=1)\n",
    "        EP_Matrix = np.concatenate((EP_Matrix, EP_Matrix_3),axis=1)\n",
    "        Com_SM = np.concatenate((similarity_output, SP_Matrix_1),axis=0)\n",
    "        Com_SM = np.concatenate((Com_SM, EP_Matrix_1),axis=0)\n",
    "        Com_SM = np.concatenate((Com_SM, SP_Matrix.T),axis=1)\n",
    "        Com_SM = np.concatenate((Com_SM, EP_Matrix.T),axis=1)       \n",
    "\n",
    "\n",
    "    return Com_SM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP NEED TO ADD HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(SM_PTS):\n",
    "    G = nx.from_numpy_matrix(SM_PTS, create_using=nx.Graph)\n",
    "    layout = nx.spring_layout(G)\n",
    "    sizes = len(SM_PTS)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_MST(G):\n",
    "    layout = nx.spring_layout(G)\n",
    "    T=nx.minimum_spanning_tree(G)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Dijkstra(T):\n",
    "    Dij = nx.dijkstra_path(T,258,259)\n",
    "    return Dij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doing_miscellaneous_work(Dijkstra_output):\n",
    "    global Counter\n",
    "    a = []\n",
    "    for x in range(len(Dijkstra_output)):\n",
    "        Counter = Counter +1 \n",
    "        Index = Dijkstra_output[x]\n",
    "        a.append(list(One_view[Index]))\n",
    "    P_TS = np.array(a)\n",
    "    return P_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_DTW_PTS(Miscellaneous_output):\n",
    "    path, dist = dtw_path(finalarray_test_data, Miscellaneous_output)\n",
    "    if(dist>0):\n",
    "        PTS_Results_List.append(dist)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_all_fun(SM_PTS):\n",
    "    \n",
    "    graph_output = generate_graph(SM_PTS)\n",
    "    MST_output_1 =  generate_MST(graph_output)\n",
    "    Dijkstra_output = generate_Dijkstra(MST_output_1)\n",
    "    Miscellaneous_output = doing_miscellaneous_work(Dijkstra_output)\n",
    "    generate_DTW_PTS(Miscellaneous_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range (1,3):\n",
    "    \n",
    "    interation_num = 4\n",
    "    for i in range (1,interation_num):\n",
    "        SM_PTS = Adding_start_end_point_PTS(Com_SM,i)\n",
    "        Run_all_fun(SM_PTS)\n",
    "        \n",
    "     \n",
    "    dictionary_PTS[y] = PTS_Results_List\n",
    "    PTS_Results_List = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [12.416535255448649, 12.310865949354351, 12.495988946710556],\n",
       " 2: [12.416535255448649, 12.310865949354351, 12.495988946710556]}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_PTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
