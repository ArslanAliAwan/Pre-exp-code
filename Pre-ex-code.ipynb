{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from copy import copy, deepcopy\n",
    "from scipy.io import arff\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "from sklearn.metrics.pairwise import euclidean_distances, pairwise_distances\n",
    "from sklearn.utils import check_random_state\n",
    "from scipy.spatial import distance\n",
    "from tslearn.soft_dtw_fast import *\n",
    "from tslearn.cysax import *\n",
    "from tslearn.metrics import dtw, dtw_path,dtw_path_from_metric,soft_dtw\n",
    "from tslearn.utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Training and Testing Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension1_TRAIN.arff')\n",
    "data2 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension2_TRAIN.arff')\n",
    "data3 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension3_TRAIN.arff')\n",
    "\n",
    "Test_data1 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension1_TEST.arff')\n",
    "Test_data2 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension2_TEST.arff')\n",
    "Test_data3 = arff.loadarff('/Users/arslanaliawan/Desktop/Pre-experiment/Multivariate_arff/CharacterTrajectories/CharacterTrajectoriesDimension3_TEST.arff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D1 = pd.DataFrame(data1[0])\n",
    "df_D2 = pd.DataFrame(data2[0])\n",
    "df_D3 = pd.DataFrame(data3[0])\n",
    "\n",
    "Test_df_D1 = pd.DataFrame(Test_data1[0])\n",
    "Test_df_D2 = pd.DataFrame(Test_data2[0])\n",
    "Test_df_D3 = pd.DataFrame(Test_data3[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Over the data, as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D1 =df_D1.apply(lambda x : x.fillna(method='ffill'), axis=1) \n",
    "df_D2 =df_D2.apply(lambda x : x.fillna(method='ffill'), axis=1)\n",
    "df_D3 =df_D3.apply(lambda x : x.fillna(method='ffill'), axis=1) \n",
    "\n",
    "Test_df_D1 =Test_df_D1.apply(lambda x : x.fillna(method='ffill'), axis=1) \n",
    "Test_df_D2 =Test_df_D2.apply(lambda x : x.fillna(method='ffill'), axis=1)\n",
    "Test_df_D3 =Test_df_D3.apply(lambda x : x.fillna(method='ffill'), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D1 = df_D1.drop('target', axis=1)\n",
    "df_D2 = df_D2.drop('target', axis=1)\n",
    "df_D3 = df_D3.drop('target', axis=1)\n",
    "\n",
    "Test_df_D1 = Test_df_D1.drop('target', axis=1)\n",
    "Test_df_D2 = Test_df_D2.drop('target', axis=1)\n",
    "Test_df_D3 = Test_df_D3.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sort_Dim_1 = np.expand_dims(df_D1.values.reshape(-1),axis=1)\n",
    "Sort_Dim_2 = np.expand_dims(df_D2.values.reshape(-1),axis=1)\n",
    "Sort_Dim_3 = np.expand_dims(df_D3.values.reshape(-1),axis=1)\n",
    "\n",
    "Sort_Test_Dim_1 = np.expand_dims(Test_df_D1.values.reshape(-1),axis=1)\n",
    "Sort_Test_Dim_2 = np.expand_dims(Test_df_D2.values.reshape(-1),axis=1)\n",
    "Sort_Test_Dim_3 = np.expand_dims(Test_df_D3.values.reshape(-1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_View = np.concatenate((Sort_Dim_1, Sort_Dim_2),axis=1)\n",
    "Training_View = np.concatenate((Training_View, Sort_Dim_3),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258804, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_View.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_View = np.concatenate((Sort_Test_Dim_1, Sort_Test_Dim_2),axis=1)\n",
    "Testing_View = np.concatenate((Testing_View, Sort_Test_Dim_3),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalarray_test_data = Testing_View[:][0:182]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalarray_test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_rows = 258804\n",
    "Sample_Percentage = 0\n",
    "Number_of_run= 0\n",
    "Length_RTS = 0\n",
    "global Sub_Sample_copy_PTS \n",
    "Training_Results_List = []\n",
    "PTS_Results_List = []\n",
    "Store_Avg_list = []\n",
    "dictionary = dict()\n",
    "dictionary_RTS = dict()\n",
    "dictionary_RTS_all = dict()\n",
    "dictionary_PTS = dict()\n",
    "dictionary_PTS_for_all_change = dict()\n",
    "RTS_short_list_Results_List = []\n",
    "Starting_point = Testing_View[:][0:1]\n",
    "End_point = Testing_View[:][181:182]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for both RTS & PTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_Percentage(Sample_Percentage):\n",
    "    Required_one_view_length = Total_rows * (Sample_Percentage/100)\n",
    "    Required_one_view_length = round(Refining_Percentage)   \n",
    "    return Required_one_view_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_One_View(Required_one_view_length):\n",
    "    One_V = Training_View[:][0:Refining_Percentage]\n",
    "    return One_V\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Required_one_view_length = Calculate_Percentage(10)\n",
    "One_view = Make_One_View(Required_one_view_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25880, 3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "One_view.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions body for Random TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_random_row(One_view,Length_RTS):\n",
    "    \n",
    "    number_of_rows = One_view.shape[0]\n",
    "    random_indices = np.random.choice(number_of_rows, size=Length_RTS, replace=False)\n",
    "    random_rows = One_view[random_indices, :]\n",
    "    return random_rows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adding_start_end_point(random_rows):\n",
    "    Output_TS = np.concatenate((Starting_point, random_rows),axis=0)\n",
    "    Output_TS = np.concatenate((Output_TS, End_point),axis=0)\n",
    "    return Output_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_Random_DTW(Output_TS,Len_RTS):\n",
    "    path, dist = dtw_path(finalarray_test_data, Output_TS)\n",
    "    if(dist>0 and Len_RTS >150 ):\n",
    "        \n",
    "        Training_Results_List.append(dist)  \n",
    "    else:\n",
    "        RTS_short_list_Results_List.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Length_RTS = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_rows = Get_random_row(One_view,Length_RTS)\n",
    "Output_TS = Adding_start_end_point(random_rows)\n",
    "Calculate_Random_DTW(Output_TS,Length_RTS) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20.659049110703304]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_Results_List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions body for Pseudo TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_similarity_matrix(Complete_PTS):\n",
    "    ED_Matrix = distance.cdist(Complete_PTS, Complete_PTS, 'euclidean')\n",
    "    return ED_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(similarity_output):\n",
    "    G = nx.from_numpy_matrix(similarity_output, create_using=nx.Graph)\n",
    "    layout = nx.spring_layout(G)\n",
    "    sizes = len(similarity_output)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_MST(G):\n",
    "    layout = nx.spring_layout(G)\n",
    "    T=nx.minimum_spanning_tree(G)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Dijkstra(T):\n",
    "    Dij = nx.dijkstra_path(T,0,181)\n",
    "    return Dij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doing_miscellaneous_work(Dijkstra_output):\n",
    "    a = []\n",
    "    for x in range(len(Dijkstra_output)):\n",
    "    \n",
    "        Index = Dijkstra_output[x]\n",
    "        a.append(list(Complete_PTS[Index]))\n",
    "    P_TS = np.array(a)\n",
    "    return P_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_DTW_PTS(Miscellaneous_output):\n",
    "    path, dist = dtw_path(finalarray_test_data, Miscellaneous_output)\n",
    "    if(dist>0):\n",
    "        PTS_Results_List.append(dist)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adding_start_end_point_PTS(Pseudo_TS,y):\n",
    "    if(y==1):\n",
    "        SP = [Testing_View[:][0]]\n",
    "        EP = [Testing_View[:][181]]\n",
    "        Output_PTS = np.concatenate((SP, Pseudo_TS),axis=0)\n",
    "        Output_PTS = np.concatenate((Output_PTS, EP),axis=0)\n",
    "    else:\n",
    "        p =182\n",
    "        SP = [Testing_View[:][p*(y-1)]]\n",
    "        EP = [Testing_View[:][((y*p)-1)]]\n",
    "        Output_PTS = np.concatenate((SP, Pseudo_TS),axis=0)\n",
    "        Output_PTS = np.concatenate((Output_PTS, EP),axis=0)\n",
    "    return Output_PTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_all_fun(Complete_PTS):\n",
    "    similarity_output = generate_similarity_matrix(Complete_PTS)\n",
    "    graph_output = generate_graph(similarity_output)\n",
    "    MST_output_1 =  generate_MST(graph_output)\n",
    "    Dijkstra_output = generate_Dijkstra(MST_output_1)\n",
    "    Miscellaneous_output = doing_miscellaneous_work(Dijkstra_output)\n",
    "    generate_DTW_PTS(Miscellaneous_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "Refining_Percentage = Calculate_Percentage(20)\n",
    "Sub_Sampling = Random_Part(Refining_Percentage)\n",
    "Sub_Sampling_PTS = Sub_Sampling[:][1:181]\n",
    "Pseudo_TS = Sub_Sampling_PTS\n",
    "Complete_PTS = Adding_start_end_point_PTS(Pseudo_TS,y)\n",
    "Run_all_fun(Complete_PTS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
